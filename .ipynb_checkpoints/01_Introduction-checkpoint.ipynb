{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a73f5a-2085-40de-a892-adbf16d43627",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning in Python \n",
    "\n",
    "This lesson provides an introduction to some of the common methods and terminologies used in machine learning research. We will cover areas such as data preparation and resampling, model building, and model evaluation. \n",
    "\n",
    "It is a prerequisite for the other lessons in the machine learning curriculum. In later lessons we explore tree-based models for prediction, neural networks for image classification, and responsible machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea973973-21ef-4bfa-adbb-58f0a6d18447",
   "metadata": {},
   "source": [
    "## Goal - Predicting the outcome of critical care patients \n",
    "\n",
    "Critical care units are home to sophisticated monitoring systems, helping carers to support the lives of the sickest patients within a hospital. These monitoring systems produce large volumes of data that could be used to improve patient care.\n",
    "\n",
    "Our goal is to predict the outcome of critical patients using physiological data available on the first day of admission to the intensive care unit. These predictions could be used for resource planning or to assist with family discussions. \n",
    "\n",
    "The dataset used in this lesson was extracted from the [eICU Collaborative Research Database](https://www.nature.com/articles/sdata2018178), a publicly available dataset comprising de-identified physiological data collected from critically ill patients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b9b59-b0f0-4780-8ddf-89d9ff983b4e",
   "metadata": {},
   "source": [
    "# Part 1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f30d67-7df4-46cd-a7c4-5cfb87fd5aad",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* What is machine learning?\n",
    "* What is the relationship between machine learning, AI, and statistics?\n",
    "* Understand the difference between supervised and unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05790364-1434-4c01-9f01-798a0e584660",
   "metadata": {},
   "source": [
    "## Rule-based programming \n",
    "\n",
    "We are all familiar with the idea of applying rules to data to gain insights and make decisions. For example, we learn that human body temperature is ~37 Â°C, and that higher or lower temperatures can be cause for concern. \n",
    "\n",
    "As programmers we understand how to codify these rules. If we were developing software for a hospital to flag patients at risk of deterioration, we might create early-warning rules such as those below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5404b1-4232-4014-a175-af8998f0c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_fever(temp_c):\n",
    "    if temp_c > 38:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f24ddf3-2198-4b34-a1d4-8c132f161b25",
   "metadata": {},
   "source": [
    "## What is machine learning?\n",
    "\n",
    "__Machine Learning (ML)__ is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data and thus perform tasks without explicit instructions. Recently, artifical neural networks have been able to surpass many previous approaches in performance. \n",
    "\n",
    "__ML__ finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. When applied to business problems, it is known under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb48fa6-787b-481e-b4c4-8041047b473b",
   "metadata": {},
   "source": [
    "## Relationships to statistics\n",
    "\n",
    "Machine learning and statistics are closely related fields in terms of methods, but distinct in their principal goal: __statistics draws population inferences from a sample, while machine learning finds generalisable predictive patterns__. \n",
    "\n",
    "Conventional statistical analyses require the a priori selection of a model most suitable for the study data set. In addition, only significant or theoretically relevant variables based on previous experience are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather, the data shape the model by detecting underlying patterns. The more variables (input) used to train the model, the more accurate the ultimate model will be. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d7b686-3884-4045-872d-f0df6c7afb2f",
   "metadata": {},
   "source": [
    "## Relationships to AI and deep learning\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/AI_hierarchy.svg/399px-AI_hierarchy.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ed8c7-07c5-4100-bdeb-6176011b44a5",
   "metadata": {},
   "source": [
    "## Machine learning approaches\n",
    "\n",
    "Machine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigms, depending on the nature of the \"signal\" or \"feedback\" available to the learning system:\n",
    "\n",
    "* __Supervised learning:__ The computer is presented with example inputs and their desired outputs, given by a \"teacher\", and the goal is to learn a general rule that maps inputs to outputs.\n",
    "* __Unsupervided learning:__ No labels are given to the learning algorithm, leaving it on its own find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).\n",
    "* __Reinforcement learning:__ A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving vehicle or playing a game against an opponent). As it navigates its problem space, the program is provided feedback that's analogous to rewards, which it tries to maximise.\n",
    "\n",
    "Although each algorithm has advantages and limitations, no single algorithm works for all problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0df300-d636-43e4-9d8f-bf8fda9e390e",
   "metadata": {},
   "source": [
    "## Machine learning models\n",
    "\n",
    "A __machine learning model__ is a type of mathematical model that, after being \"trained\" on a given dataset, can be used to make predictions or classifications on new data. During training, a learning algorithm iteratively adjusts the model's internal parameters to minimise errors in its predictions. By extension, the term \"model\" can refer to several levels of specificity, from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned. \n",
    "\n",
    "Various types of models have been used and researched for machine learning systems, picking the best model for a task is called model selection.\n",
    "\n",
    "* __Artificial neural networks (ANNs):__ are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/300px-Colored_neural_network.svg.png)\n",
    "\n",
    "* __Decision trees:__ decision tree learning uses a decision tree as a predictive model to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modeling approaches used in statistics, data mining, and machine learning.\n",
    "\n",
    "![](https://i0.wp.com/why-change.com/wp-content/uploads/2021/11/Decision-Tree-elements-2.png?resize=715%2C450&ssl=1)\n",
    "\n",
    "* __Support-vector machines (SVMs):__ also known as support-vector networks, are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category.\n",
    "\n",
    "![](https://i.ytimg.com/vi/ny1iZ5A8ilA/maxresdefault.jpg)\n",
    "\n",
    "* __Regression analysis:__ encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is linear repression, where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares. The latter is often extended by regularisation methods to mitigate overfitting and bias, as in ridge regression. When dealing with non-linear problems, go-to models include polynomial regression, logistic regression (often used in statistical classification) or even kernel regression, which introduces non-linearity by taking advantage of the kernel trick to implicitly map input variables to higher-dimensional space.\n",
    "\n",
    "![](https://www.questionpro.com/blog/wp-content/uploads/2019/03/Regression-Analysis_1.jpg)\n",
    "\n",
    "* __Bayesian networks:__ a Bayesian network is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. \n",
    "\n",
    "![](https://www.nbertagnolli.com/assets/Bayes_Nets/figure_01.png) \n",
    "\n",
    "* __Gaussian processes:__ a Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution, and it relies on a pre-defined covariance function, or kernel, that models how pairs of points relate to each other depending on their locations. Gaussian processes are popular surrogate models in Bayesian optimisation used to do hyperparameter optimisation.\n",
    "\n",
    "![](https://www.researchgate.net/profile/Florent-Leclercq/publication/327613136/figure/fig1/AS:749406701776896@1555683889137/Illustration-of-Gaussian-process-regression-in-one-dimension-for-the-target-test.png)\n",
    "\n",
    "* __Genetic algorithms:__ a genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the process of natural selection, using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1400/1*BYDJpa6M2rzWNSurvspf8Q.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f48646e-4c26-4f9e-906f-1c288da1b91c",
   "metadata": {},
   "source": [
    "## Key points\n",
    "\n",
    "* Machine learning borrows heavily from fields such as statistics and computer science.\n",
    "* In machine learning, models learn rules from data.\n",
    "* In supervised learning, the target in our training data is labelled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3dcc64-475e-4b3f-890b-13f8ed2ac276",
   "metadata": {},
   "source": [
    "# Part 2 - Data preparation\n",
    "\n",
    "__Objectives:__\n",
    "\n",
    "* What are the common steps in data preparation?\n",
    "* Why do we partition data at the start of a project?\n",
    "* What is the purpose of setting a random state when partitioning?\n",
    "* Should we impute missing values before or after partitioning?\n",
    "* Explore characteristics of our dataset.\n",
    "* Partition data into training and test sets.\n",
    "* Encode categorical values.\n",
    "* Use scaling to pre-process features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e48d4-ea0b-437c-87e8-c1e0ecc8cfdf",
   "metadata": {},
   "source": [
    "## Sourcing and accessing data\n",
    "\n",
    "Machine learning helps us to find patterns in data, so sourcing and understanding data is key. Unsuitable or poorly managed data will lead to a poor project outcome, regardless of the modelling approach. \n",
    "\n",
    "We will use an open access subset of the [eICU Collaborative Research Database](https://eicu-crd.mit.edu/about/eicu/), a publicly available dataset comprising deidentified physiological data collected from critically ill patients. For simplicity, we will be working with a pre-prepared CSV file that comprises data extracted from a [demo version of the dataset](https://physionet.org/content/eicu-crd-demo/2.0.1/).\n",
    "\n",
    "Let's begin by loading this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19483f7-d3b2-41f6-9e9f-4992be935654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the data\n",
    "cohort = pd.read_csv('./eicu_cohort.csv')\n",
    "cohort.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f85d326-29ab-4284-910a-5068c80f0655",
   "metadata": {},
   "source": [
    "## Knowing the data \n",
    "\n",
    "Before moving ahead on a project, it is important to understand the data. Having someone with domain knowledge - and ideally first hand knowledge of the data collection process - helps us to design a sensible task and to use data effectively. \n",
    "\n",
    "Summarising data is an important first step. We will want to know aspects of the data such as: extent of missingness; data types; numbers of observations. One common step is to view summary characteristics (for example, see [Table 1](https://www.nature.com/articles/s41746-018-0029-1/tables/1) of the paper by Rajkomar et al.).\n",
    "\n",
    "Let's generate a similar table for ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee9ada2-be50-4a57-bae6-e2e9f0f39891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tableone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40335cca-4dfc-49c8-9e37-b4ff4f12d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tableone import tableone\n",
    "\n",
    "# rename columns\n",
    "rename = {\n",
    "    \"unabridgedhosplos\": \"length of stay\",\n",
    "    \"meanbp\": \"mean blood pressure\",\n",
    "    \"wbc\": \"white cell count\"\n",
    "}\n",
    "\n",
    "# view summary \n",
    "t1 = tableone(cohort, groupby=\"actualhospitalmortality\", rename=rename)\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37049c6-ce0e-4f30-a0c0-bd3878512b3c",
   "metadata": {},
   "source": [
    "__Exercise:__\n",
    "\n",
    "* What is the approximate percent mortality in the eICU cohort?\n",
    "* Which variables appear noticeably different in the \"Alive\" and \"Expired\" groups?\n",
    "* How does the in-hospital mortality differ between the eICU cohort and the ones in [Rajkomar et al](https://www.nature.com/articles/s41746-018-0029-1/tables/1)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ee8672-6c23-4272-bfba-0e11cb77e8c2",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "It is often the case that our data includes categorical values. In our case, for example, the binary outcome we are trying to predict - in hospital mortality - is recorded as \"ALIVE\" and \"EXPIRED\". Some models can cope with taking this text as input, but many cannot. We can use label encoding to convert the categorical values to numerical representations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdef914-2502-478b-9322-8b5607ae3456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check current data types of each column\n",
    "cohort.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a4bde-a697-46a4-99df-202ea1e602d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c41eb-1e58-4538-8198-7f7276dc6e03",
   "metadata": {},
   "source": [
    "* `object`: the default type to store text data in pandas\n",
    "* `float64`: floating point numbers\n",
    "* `int64`: integers\n",
    "\n",
    "Check the documentation for [pandas.DataFrame.dtypes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161d510-5629-4e87-bd8f-cdfd270d983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column \"actualhospitalmortality\" to a categorical type\n",
    "categories = ['ALIVE', 'EXPIRED']\n",
    "cohort['actualhospitalmortality'] = pd.Categorical(cohort['actualhospitalmortality'], categories=categories)\n",
    "cohort.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3df60b7-a9a8-4860-9f1c-4d4e3fd27958",
   "metadata": {},
   "source": [
    "Check the documentation for [pandas.Categorical](https://pandas.pydata.org/docs/reference/api/pandas.Categorical.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb1f9b-52f2-4b8f-b33b-bdcc8d7cbf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the encoded value to a new column\n",
    "cohort['actualhospitalmortality_enc'] = cohort['actualhospitalmortality'].cat.codes\n",
    "cohort[['actualhospitalmortality', 'actualhospitalmortality_enc']].head()\n",
    "cohort.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffc6f38-cda1-4a43-8598-8fe9e5708846",
   "metadata": {},
   "source": [
    "Let's encode the gender in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7704842-3945-42d5-a0b8-600dbea174a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort['gender'] = pd.Categorical(cohort['gender'])\n",
    "cohort['gender'] = cohort['gender'].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a7231-72ca-425f-a4db-860381c5485a",
   "metadata": {},
   "source": [
    "## Partitioning\n",
    "\n",
    "Typically we will want to split our data into a training set and \"held-out\" test set. The training set is used for building our model and our test set is used for evaluation. A split of ~70% training, 30% test is common. \n",
    "\n",
    "![](https://carpentries-incubator.github.io/machine-learning-novice-python/fig/train_test.png)\n",
    "\n",
    "To ensure reproducibility, we should set the random state of the splitting method. This means that Python's random number generator will produce the same \"random\" split in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a5965-d9b1-4495-83e0-9add37c70783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f82f3f-ba37-4ecd-9e80-a35de9b8f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = cohort.drop('actualhospitalmortality', axis=1)\n",
    "y = cohort['actualhospitalmortality']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8a75d6-b2da-4380-9a92-8bb8fbf8b48e",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "Certain types of models - for example some decision trees - are able to implicitly handle missing data. For logistic regression, we need to impute values. We will take a simple approach of replacing with the median. \n",
    "\n",
    "With physiological data, imputing the median typically implies that the missing observation is not a cause for concern.\n",
    "\n",
    "To avoid data leaking between our training and test sets, we take the median from the training set only. The training median is then used to impute missing values in the held-out test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f670ea9-4a47-40cb-bfc2-5a5cd4efeefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values from the training set\n",
    "x_train = x_train.fillna(x_train.median())\n",
    "x_test = x_test.fillna(x_train.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe7f613-0ede-4208-912a-a4888edc72bc",
   "metadata": {},
   "source": [
    "It is often the case that data is not missing at random. For example, the presence of blood sugar observations may indicate suspected diabetes. To use this information, we can choose to create missing data features comprising of binary \"is missing\" flags. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c2b02-96f8-4248-9a93-23340b06b3c2",
   "metadata": {},
   "source": [
    "## Normalisation\n",
    "\n",
    "Lastly, normalisation - scaling variables so that they span consistent ranges - can be important, particularly for models that rely on distance based optimisation metrics. \n",
    "\n",
    "As with creating train and test splits, it is a common enough task that there are plenty of pre-built functions for us to choose from. We will choose the [Min-Max Scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) from the sklearn package, which scales each feature between zero and one. \n",
    "\n",
    "$$\n",
    "  x_{std} = \\frac{x - x_{min}}{x_{max} - x_{min}}\n",
    "$$\n",
    "$$\n",
    "  x_{scaled} - x_{std} * (x_{max} - x_{min}) + x_{min}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb0778-6c1f-4697-bee4-671231c2d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#fit the scaler on the training dataset\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# scale the training set\n",
    "x_train = scaler.transform(x_train)\n",
    "\n",
    "# scale the test set \n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b99cc1-12fd-422c-ac21-11ce9a80c987",
   "metadata": {},
   "source": [
    "* __MinMaxScaler.fit:__ compute the minimum and maximum to be used for later scaling.\n",
    "* __MinMaxScaler.transform:__ scale features of dataset according to feature_range, where feature_range=(min, max).\n",
    "\n",
    "Outliers in features can have a negative impact on the normalisation process - they can essentially squash non-outliers into a small space - so they may need special treatment (for example, a [RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff82d4-54e7-4b81-b62c-3a09ae6f23b0",
   "metadata": {},
   "source": [
    "## Key points\n",
    "\n",
    "* Data pre-processing is arguably the most important task in machine learning.\n",
    "* Data is typically partitioned into training and test sets.\n",
    "* Setting random states helps to promote reproducibility. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4269d416-8aa2-473c-9adb-1b37826d1983",
   "metadata": {},
   "source": [
    "# Part 3 - Learning \n",
    "\n",
    "__Objectives:__\n",
    "\n",
    "* How do machines learn?\n",
    "* How can machine learning help us to make predictions?\n",
    "* Why is it important to be able to quantify the error in our models?\n",
    "* What is an example of a loss function?\n",
    "* Understand the importance of quantifying error.\n",
    "* Code a linear regression model that takes inputs, weights, and bias.\n",
    "* Code a loss function that quantifies model error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cebf66a-35c0-4b22-aa69-a6041f4d21a5",
   "metadata": {},
   "source": [
    "## How do machines learn?\n",
    "\n",
    "How do machines learn? Typically we are given examples and we learn rules through trial and error. Machines aren't that different! In the context of machine learning, we talk about how a model \"fits\" to the data.\n",
    "\n",
    "Our model has a number of tweakable parameters. We need to find the optimal values for those parameters such that our model outputs the \"best\" predictions for a set of input variables. \n",
    "\n",
    "![](https://carpentries-incubator.github.io/machine-learning-novice-python/fig/ml_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f6b41c-f7c5-4c7f-b1fa-2cdb35a4f683",
   "metadata": {},
   "source": [
    "## Loss functions\n",
    "\n",
    "Finding the best model means defining \"best\". We need to have some way of quantifying the difference between a \"good\" model (capable of making useful predictions) vs a \"bad\" model (not capable of making useful predictions).\n",
    "\n",
    "Loss functions are crucial for doing this. They allow us to quantify how closely our predictions fit to the known target values. You will hear \"objective function\", \"error function\", and \"cost function\" used in a similar way.\n",
    "\n",
    "Mean squared error is a common example of a loss function, often used for linear regression. For each prediction, we measure the distance between the known target value ($y$) and our prediction ($y_{hat}$), and then we take the square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3010c4fb-5a89-4e8f-9bff-e1fda964ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create sample labelled data\n",
    "data = {\n",
    "    'x': [1,2,3,4,5],\n",
    "    'y': [-0.5,1,2,4,7]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# add predictions\n",
    "df['y_hat'] = [0,2,4,6,8]\n",
    "\n",
    "# plot the data\n",
    "ax = df.plot(x='x', y='y', kind='scatter', xlim=[0,6], ylim=[-1,9])\n",
    "\n",
    "# plot the predictions\n",
    "ax.plot(df['x'], df['y_hat'], color='blue')\n",
    "\n",
    "# plot error\n",
    "ax.vlines(x=df['x'], ymin=df['y'], ymax=df['y_hat'], color='red', linestyle='dashed')\n",
    "ax.text(x=3.1, y=3, s='Error')\n",
    "ax.set_title('Prediction error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd5e1a6-cd7a-46a6-9bec-16226d43d25f",
   "metadata": {},
   "source": [
    "The further away from the data points our line gets, the bigger the error. Our best model is the one with the smallest error. Mathematically, we can define the mean squared error as:\n",
    "\n",
    "$$\n",
    "  mse = \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y_i})^2\n",
    "$$\n",
    "\n",
    "* $mse$ is the Mean Squared Error.\n",
    "* $y_i$ is the actual value.\n",
    "* $\\hat{y_i}$ is the predicted value.\n",
    "* $\\sum$ means we are taking the sum of the difference.\n",
    "* $n$ is the number of observations, so $\\frac{1}{n}$ means we are taking the mean.\n",
    "\n",
    "We could implement this in our codes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46005578-bf15-487d-af10-ae7ee62c95e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def loss(y, y_hat):\n",
    "    distances = y - y_hat\n",
    "    squared_distances = np.square(distances)\n",
    "    return np.mean(squared_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0cbc87-1553-44b0-a21f-998ee2e277b9",
   "metadata": {},
   "source": [
    "## Minimising the error\n",
    "\n",
    "Our goal is to find the \"best\" model. We have defined best as being the model with parameters that give us the smallest mean squared error. We can write this as:\n",
    "\n",
    "$$\n",
    "  argmin\\frac{1}{n}\\sum{i=1}^{n}(y_i - \\hat{y_i})^2\n",
    "$$\n",
    "\n",
    "Let's stop and look at what this loss function means. We'll plot the squared error for a range of values to demonstrate how loss scales as the difference between $y$ and $\\hat{y}$ increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32e3961-76d1-4c7d-9345-e8b01d581f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-50, 50, 0.05)\n",
    "y = np.square(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('Difference between y and y_hat')\n",
    "plt.ylabel('Loss (squared error)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91be10e7-f310-49f6-a271-fc9511b19f33",
   "metadata": {},
   "source": [
    "As we can see, our loss rapidly increases as predictions ($\\hat{y}$) move away from the true values ($y$). The result is that outliers have a strong influence on our model fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d372987-6359-41fb-98a6-641ed685a773",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "\n",
    "In machine learning, there is typically a training step where an algorithm is used to find the optimal set of model parameters (i.e. those parameters that give the minimum possible error). This is the essence of machine learning.\n",
    "\n",
    "![](https://carpentries-incubator.github.io/machine-learning-novice-python/fig/ml_model_loss.png)\n",
    "\n",
    "There are many approaches to optimisation. [Gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) is a popular approach.\n",
    "\n",
    "__Exercise:__\n",
    "\n",
    "* What does a loss function quantify?\n",
    "* What is an example of a loss function?\n",
    "* What is happening when a model is trained?\n",
    "\n",
    "Now that we've touched on how machines learn, we'll tackle the problem of predicting the outcome of patients admitted to intensive care units in hospitals across the United States. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420ec3f-3991-40f7-8a2a-8ea138eb5fa8",
   "metadata": {},
   "source": [
    "## Key points\n",
    "\n",
    "* Loss functions allow us to define a good model.\n",
    "* $y$ is a known target. $\\hat{y}(y_{hat})$ is a prediction.\n",
    "* Mean squared error is an example of a loss function.\n",
    "* After defining a loss function, we search for the optimal solution in a process known as \"training\".\n",
    "* Optimisation is at the heart of machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7a749d-ffac-44da-bdd5-4df2743a016d",
   "metadata": {},
   "source": [
    "# Part 4 - Modelling\n",
    "\n",
    "__Objectives:__\n",
    "\n",
    "* Broadly speaking, when talking about regression and classification, how does the prediction target differ?\n",
    "* Would linear regression be most useful for a regression or classification task? How about logistic regression?\n",
    "* Use a linear regression model for prediction.\n",
    "* Use a logistic regression model for prediction.\n",
    "* Set a decision boundary to predict an outcome from a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8774a5-e7b6-4e31-a613-49e7ac34a360",
   "metadata": {},
   "source": [
    "## Regression vs Classification\n",
    "\n",
    "Predicting one or more classes is typically referred to as __classification__. The task of predicting a continuous variable on the other hand (for example, length of hospital stay) is typically referred to as a __regression__.\n",
    "\n",
    "Note that \"regression models\" can be used for both regression tasks and classification tasks. \n",
    "\n",
    "We will begin with a linear regression, a type of model borrowed from statistics that has all of the hallmarks of machine learning, which can be written as:\n",
    "\n",
    "$$\n",
    "  \\hat{y} = wX + b\n",
    "$$\n",
    "\n",
    "Our predictions can be denoted by $\\hat{y}$ (pronounced \"y hay\") and our explanatory variables (or \"features\") denoted by $X$. In our case, we will use a single feature: the APACHE-IV score, a measure of severity of illness. \n",
    "\n",
    "There are two parameters of the model that we would like to learn from the training data:\n",
    "\n",
    "* $w$: weight.\n",
    "* $b$: bias.\n",
    "\n",
    "Could we use a linear regression for our classification task? Let's try fitting a line to our outcome data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac93eb2-379a-4380-adb0-b53cb6587c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the regression model \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "# use a single feature (apache score)\n",
    "# note: remove the reshape if fitting to more than one input variable\n",
    "X = cohort.apachescore.values.reshape(-1, 1)\n",
    "y = cohort.actualhospitalmortality_enc.values\n",
    "\n",
    "# fit the model to our data \n",
    "reg = reg.fit(X, y)\n",
    "\n",
    "# generate some data to predict y values\n",
    "buffer = 0.2 * max(X)\n",
    "X_fit = np.linspace(min(X)-buffer, max(X)+buffer, num=50)\n",
    "y_fit = reg.predict(X_fit)\n",
    "\n",
    "# plot\n",
    "plt.scatter(X, y, color='black', marker='x')\n",
    "plt.plot(X_fit, y_fit, color='red', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210aaf61-dacc-4c1e-88e5-2628c2075ffa",
   "metadata": {},
   "source": [
    "Linear regression places a line through a set of data points that minimises the error between the line and the points. It is difficult to see how a meaningful threshold could be set to predict the binary outcome in our task. The predicted values can exceed our range of outcomes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b7df8f-2127-4612-93b5-96b15b62d8d5",
   "metadata": {},
   "source": [
    "## Sigmoid function\n",
    "\n",
    "The sigmoid function (also known as a logistic function) comes to our rescue. This function gives an \"s\" shaped curve that can take a number and map it into a value between 0 and 1:\n",
    "\n",
    "$$\n",
    "  f: \\mathbb{R} \\mapsto (0,1)\n",
    "$$\n",
    "\n",
    "The sigmoid function can be written as:\n",
    "\n",
    "$$\n",
    "  f(x) = \\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "\n",
    "Let's take a look at a curve generated by this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e590c5e-3e16-4e0f-8ba5-687b6cd38af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, k=0.1):\n",
    "    \"\"\"\n",
    "    Sigmoid function.\n",
    "    Adjust k to set slope.\n",
    "    \"\"\"\n",
    "    s = 1/(1+np.exp(-x/k))\n",
    "    return s\n",
    "\n",
    "# generate some x values \n",
    "x = np.linspace(-1, 1, 50)\n",
    "\n",
    "plt.plot(x, sigmoid(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cebeb67-087b-476e-8997-23d6f844ce5d",
   "metadata": {},
   "source": [
    "We can use this to map our linear regression to produce output values that fall between 0 and 1.\n",
    "\n",
    "$$\n",
    "  f(x) = \\frac{1}{1 + e^{-(wX+b)}}\n",
    "$$\n",
    "\n",
    "As an added benefit, we can interpret the output values as a probability. The probability relates to the positive class (the outcome with value \"1\"), which in our case is in-hospital mortality (\"EXPIRED\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06409094-d59b-4c3f-aaf4-22abf9b29e2e",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "Logistic regressions are powerful models that often outperform more sophisticated machine learning models. In machine learning studies, it is typical to include performance of a logistic regression model as a baseline.\n",
    "\n",
    "We need to find the parameters for the best-fitting logistic model given our data. As before, we do this with the help of a loss function that quantifies error. Our goal is to find the parameters of the model that minimise the error. With this model, we no longer use least squares due to the model's non-linear properties. Instead we will use log loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc925fb-4ec7-4e2c-8316-35837d5a9528",
   "metadata": {},
   "source": [
    "## Training (or fitting) the model\n",
    "\n",
    "As is typically the case when using machine learning packages, we don't need to code the loss function ourselves. The function is implemented as part of our machine learning package (in this case [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)). Let's try fitting a Logistic Regression to our data.\n",
    "\n",
    "__Exercise:__ \n",
    "\n",
    "* Following the previous example for a linear regression, fit a logistic regression to your data and create a new plot. How do the predictions differ from before? Hint: `from sklearn.linear_model import LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4f13b-4828-40e2-9615-e27d03dc0631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the regression model \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg = LogisticRegression()\n",
    "\n",
    "# use a single feature (apache score)\n",
    "# note: remove the reshape if fitting to more than one input variable\n",
    "X = cohort.apachescore.values.reshape(-1, 1)\n",
    "y = cohort.actualhospitalmortality_enc.values\n",
    "\n",
    "# fit the model to our data \n",
    "reg = reg.fit(X, y)\n",
    "\n",
    "# generate some data to predict y values\n",
    "buffer = 0.2 * max(X)\n",
    "X_fit = np.linspace(min(X)-buffer, max(X)+buffer, num=50)\n",
    "y_fit = reg.predict(X_fit)\n",
    "\n",
    "# plot\n",
    "plt.scatter(X, y, color='black', marker='x')\n",
    "plt.plot(X_fit, y_fit, color='red', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caabbf17-0434-4a06-8fd2-56a769fcf42e",
   "metadata": {},
   "source": [
    "## Decision boundary\n",
    "\n",
    "Now that our model is able to output the probability of our outcome, we can set a decision boundary for the classification task. For example, we could classify probabilities of <0.5 as \"ALIVE\" and >=0.5 as \"EXPIRED\". Using this approach, we can predict outcomes for a given input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3580e19-52aa-4a46-a07a-649ec3139ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[90]]\n",
    "\n",
    "outcome = reg.predict(x)\n",
    "probs = reg.predict_proba(x)[0]\n",
    "print(f'For x={x[0][0]}, we predict an outcome of \"{outcome[0]}\".\\n'\n",
    "      f'Class probabilities (0, 1): {round(probs[0], 2), round(probs[1], 2)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5ad63-fb97-4984-a008-89e9b118d520",
   "metadata": {},
   "source": [
    "__Key points:__\n",
    "\n",
    "* Linear regression is a popular model for regression tasks.\n",
    "* Logistic regression is a popular model for classification tasks.\n",
    "* Probabilities that can be mapped to a prediction class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054630d1-bc1e-4cec-a25f-28735ed5a9a3",
   "metadata": {},
   "source": [
    "# Part 5 - Validation\n",
    "\n",
    "__Objectives:__\n",
    "\n",
    "* What is meant by model accuracy?\n",
    "* What is the purpose of a validation set?\n",
    "* What are two types of cross validation?\n",
    "* What is overfitting?\n",
    "* Train a model to predict patient outcomes on a held-out test set.\n",
    "* Use cross validation as part of our model training process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9370698-1324-4634-a290-407512f9dfd6",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "One measure of the performance of a classification model is accuracy. Accuracy is defined as the overall proportion of correct predictions. If, for example, we take 50 shots and 40 of them hit the target, then our accuracy is 0.8 (40/50). \n",
    "\n",
    "![](https://carpentries-incubator.github.io/machine-learning-novice-python/fig/japan_ren_hayakawa.jpg)\n",
    "\n",
    "Accuracy can therefore be defined by the formula below:\n",
    "\n",
    "$$\n",
    "  Accuracy = \\frac{Correct predictions}{All predictions}\n",
    "$$\n",
    "\n",
    "What is the accuracy of our model at predicting in-hospital mortality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12db9dff-c891-4208-bdad-7ea2187f5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# define features and outcome\n",
    "features = ['apachescore']\n",
    "outcome = ['actualhospitalmortality_enc']\n",
    "\n",
    "# partition data into training and test sets\n",
    "X = cohort[features]\n",
    "y = cohort[outcome]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "# restructure data for input into model\n",
    "# note: remove the reshape if fitting to >1 input variable\n",
    "x_train = x_train.values.reshape(-1, 1)\n",
    "y_train = y_train.values.ravel()\n",
    "x_test = x_test.values.reshape(-1, 1)\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# train model\n",
    "reg = LogisticRegression(random_state=0)\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# generate prediction\n",
    "y_hat_train = reg.predict(x_train)\n",
    "y_hat_test = reg.predict(x_test)\n",
    "\n",
    "# accuracy on training set\n",
    "acc_train = np.mean(y_hat_train == y_train)\n",
    "print(f'Accuracy on training set: {acc_train: .2f}')\n",
    "\n",
    "# accuracy on test set\n",
    "acc_test = np.mean(y_hat_test == y_test)\n",
    "print(f'Accuracy on test set: {acc_test: .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c78f067-50cf-4226-bd2e-632cae19e8ae",
   "metadata": {},
   "source": [
    "* Note: The `array.ravel()` method in NumPy is used to return a contiguous flattened array.\n",
    "\n",
    "There was a slight drop in performance on out test set, but that is to be expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2394388a-b183-4d74-8573-ce53fdc4bb1c",
   "metadata": {},
   "source": [
    "## Validation set\n",
    "\n",
    "Machine learning is iterative by nature. We want to improve our model, tuning and evaluating as we go. This leads us to a problem. Using our test set to iteratively improve our model would be cheating. It is supposed to be \"held out\", not used for training. So what do we do?\n",
    "\n",
    "The answer is that we typically partition off part of our training set to use for validation. The \"validation set\" can be used to iteratively improve our model, allowing us to save our test set for the __final__ evaluation.\n",
    "\n",
    "![](https://carpentries-incubator.github.io/machine-learning-novice-python/fig/training_val_set.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8230c8c-82a4-4e55-b9f7-ae68bd6a6a27",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "Why stop at one validation set? With sampling, we can create many training sets and many validation sets, each slightly different. We can then average our findings over the partitions to give an estimate of the model's predictive performance. \n",
    "\n",
    "The family of resampling methods used for this is known as \"__cross validation__\". It turns out that one major benefit to cross validation is that it helps us to build more robust models.\n",
    "\n",
    "If we train our model on a single set of data, the model may learn rules that are overly specific (e.g. \"all patients aged 63 years survive\"). These rules will not generalise well to unseen data. When this happens, we say our model is \"__overfitted__\".\n",
    "\n",
    "If we train on multiple, subtly-different versions of the data, we can identify rules that are likely to generalise better outside our training set, helping to avoid overfitting. \n",
    "\n",
    "Two popular cross-validation methods:\n",
    "\n",
    "* K-fold cross validation\n",
    "* Leave-one-out cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce5bd7a-0427-4f76-bb66-9e142ece2dc8",
   "metadata": {},
   "source": [
    "## K-fold cross validation\n",
    "\n",
    "In K-fold cross validation, \"K\" indicates the number of times we split our data into training/validation sets. With 5-fold cross validation, for example, we create 5 separate training/validation sets. \n",
    "\n",
    "![](https://carpentries-incubator.github.io/machine-learning-novice-python/fig/k_fold_cross_val.png)\n",
    "\n",
    "With K-fold cross validation, we select our model to evaluate and then:\n",
    "\n",
    "1. Partition the training data into a training set and a validation set. An 80%, 20% split is common.\n",
    "2. Fit the model to the training set and make a record of the optimal parameters.\n",
    "3. Evaluate performance on the validation set.\n",
    "4. Repeat the process 5 times, then average the parameter and performance values.\n",
    "\n",
    "When creating our training and test sets. we needed to be careful to avoid data leaks. The same applies when creating training and validation sets. We can use a `pipeline` object to help manage this issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e1982-e76a-405a-82a2-79e61a8e6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, std\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# define dataset\n",
    "X = x_train\n",
    "y = y_train\n",
    "\n",
    "# define the pipeline \n",
    "steps = list()\n",
    "steps.append(('scaler', MinMaxScaler()))\n",
    "steps.append(('model', LogisticRegression()))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "# evaluate the model using cross-validation\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Cross-validation accuracy, mean (std): %.2f (%.2f)' % (mean(scores)*100, std(scores)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2668a7-3772-45ee-84d8-f29f6c871397",
   "metadata": {},
   "source": [
    "Leave-one-out cross validation is the same idea, except that we have many more folds. In fact, we have one fold for each data point. Each fold we leave out one data point for validation and use all of the other points for training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed88bed-677f-4960-a30d-178a612a8125",
   "metadata": {},
   "source": [
    "## Key points\n",
    "\n",
    "* Validation sets are used during model development, allowing models to be tested prior to testing on a held-out set.\n",
    "* Cross-validation is a resampling technique that creates multiple validation sets.\n",
    "* Cross-validation can help to avoid overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257816d1-59bf-4ea5-8d3a-55ead29f0fc5",
   "metadata": {},
   "source": [
    "# Part 6 - Evaluation\n",
    "\n",
    "__Objectives:__\n",
    "\n",
    "* What kind of values go into a confusion matrix?\n",
    "* What do the letters AUROC stand for?\n",
    "* Does an AUROC of 0.5 indicate our predictions were good, bad, or average?\n",
    "* In the context of evaluating performance of a classifier, what is TP?\n",
    "* Create a confusion matrix for a predictive model.\n",
    "* Use the confusion matrix to compute popular performance metrics.\n",
    "* Plot an AUROC curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d7f72f-7c1c-4916-b946-a9426c556b5f",
   "metadata": {},
   "source": [
    "## Evaluating a classification task\n",
    "\n",
    "We trained a machine learning model to predict the outcome of patients admitted to intensive care units. As there are two outcomes, we refer to this as a \"binary\" classification task. We are now ready to evaluate the model on our held-out test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa101f-b0fa-4ba1-849f-20ad7542961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# define features and outcome\n",
    "features = ['apachescore']\n",
    "outcome = ['actualhospitalmortality_enc']\n",
    "\n",
    "# partition data into training and test sets\n",
    "X = cohort[features]\n",
    "y = cohort[outcome]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state =  42)\n",
    "\n",
    "# restructure data for input into model\n",
    "# note: remove the reshape if fitting to >1 input variable\n",
    "x_train = x_train.values.reshape(-1, 1)\n",
    "y_train = y_train.values.ravel()\n",
    "x_test = x_test.values.reshape(-1, 1)\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# train model\n",
    "reg = LogisticRegression(random_state=0)\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# generate predictions\n",
    "y_hat_test = reg.predict(x_test)\n",
    "y_hat_test_proba = reg.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c3f37-030d-4d2f-987d-274cd9f09972",
   "metadata": {},
   "source": [
    "Each prediction is assigned a probability of a positive class. For example, the first 10 probabilities are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a337ca-6b99-4bd7-bf04-3d3c2b82ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = y_hat_test_proba[:,1][:10]\n",
    "rounded_probs = [round(x,2) for x in probs]\n",
    "print(rounded_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4ae4bb-10bf-4ba8-8343-9d83fe276800",
   "metadata": {},
   "source": [
    "These probabilities correspond to the following predictions, either a \"0\" (\"ALIVE\") or a 1 (\"EXPIRED\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9959364f-f423-40e2-ae8b-4e8a6b1ff2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_hat_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6623e76e-d124-4f1a-9d07-32c7625f5b35",
   "metadata": {},
   "source": [
    "In comparison with the known outcomes, we can put each prediction into one of the following categories:\n",
    "\n",
    "* __True positive__: we predict \"1\" (\"EXPIRED\") and the true outcome is \"1\".\n",
    "* __True negative__: we predict \"0\" (\"ALIVE\") and the true outcome is \"0\".\n",
    "* __False positive__: we predict \"1\" (\"EXPIRED\") and the true outcome is \"0\".\n",
    "* __False negative__: we predict \"0\" (\"ALIVE\") and the true outcome is \"1\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae3886-88c8-4569-a074-859c02b44b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779cca7e-cc6f-43c4-bf36-15850f250342",
   "metadata": {},
   "source": [
    "## Confusion matrices\n",
    "\n",
    "It is common practice to arrange these outcome categories into a \"__confusion matrix__\", which is a grid that records our predictions against the ground truth. For a binary outcome, confusion matrices are organised as follows:\n",
    "\n",
    "|| __Negative (predicted)__ | __Positive (predicted)__ |\n",
    "|:------|:----:|:----:|\n",
    "| Negative (actual) | __TN__ | FP |\n",
    "| Positive (actual) | FN | __TP__ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ef9214-4980-4c56-bf08-95d8bb5298a5",
   "metadata": {},
   "source": [
    "The sum of the cells is the total number of predictions. The diagonal from top left to bottom right indicates correct predictions. Let's visualise the results of the model in the form of a confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3cbb17-7407-47eb-986e-9a1f5a24918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_hat_test)\n",
    "class_names = cohort['actualhospitalmortality'].cat.categories\n",
    "\n",
    "disp = metrics.ConfusionMatrixDisplay.from_estimator(\n",
    "    reg, x_test, y_test, display_labels=class_names,\n",
    "    cmap=plt.cm.Blues\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd91005-43b4-44b7-bbd3-55d9b6e89db8",
   "metadata": {},
   "source": [
    "We have two columns and rows because we have a binary outcome, but you can also extend the matrix to plot multi-class classification predictions. If we had more output classes, the number of columns and rows would match the number of classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47419af8-f303-4183-9137-4a6fec270792",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "Accuracy is the overall proportion of correct predictions. Think of a dartboard. How many shots did we take? How many did we hit? Divide one by the other and that's the accuracy.\n",
    "\n",
    "Accuracy can be written as:\n",
    "\n",
    "$$\n",
    "  Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}\n",
    "$$\n",
    "\n",
    "__What was the accuracy of our model?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b42917-1eed-48b3-9be1-5c4cd89b5234",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(y_test, y_hat_test)\n",
    "print(f'Accuracy (model) = {acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f708dac-6c0c-430e-990e-508d0b44e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros(len(y_test))\n",
    "acc = metrics.accuracy_score(y_test, zeros)\n",
    "print(f'Accuracy (zeros) = {acc: .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f95e3-4f8d-47ef-8ab5-70bded8aed98",
   "metadata": {},
   "source": [
    "The problem with accuracy as a metric is that it is heavily influenced by prevalence of the positive outcome: because the proportion of 1s is relatively low, classifying everything as 0 is a safe bet. \n",
    "\n",
    "We can see that the high accuracy is possible despite totally missing our target. To evaluate an algorithm in a way that prevalence does not cloud our assessment, we often look at sensitivity and specificity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f761837-3a37-4fea-9c5c-5fdf19d3dc56",
   "metadata": {},
   "source": [
    "## Sensitivity (Recall or True Positive Rate)\n",
    "\n",
    "Sensitivity is the ability of an algorithm to predict a positive outcome when the actual outcome is positive. In our case, of the patients who die, what proportion did we correctly predict? This can be written as:\n",
    "\n",
    "$$\n",
    "  Sensitivity = Recall = \\frac{TP}{TP+FN}\n",
    "$$\n",
    "\n",
    "Because a model that calls \"1\" for everything has perfect sensitivity, this measure is not enough on its own. Alongside sensitivity we often report on specificity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2453d469-a47a-497e-80ee-7c7b66bbfad6",
   "metadata": {},
   "source": [
    "## Specificity (True Negative Rate)\n",
    "\n",
    "Specificity relates to the test's ability to correctly classify patients who survive their stay (i.e. class \"0\"). Specificity is the proportion of those who survive who are predicted to survive. The formula for specificity is:\n",
    "\n",
    "$$\n",
    "  Specificity=\\frac{TN}{FP+TN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30f7bb-337f-44cb-909c-2cbc300b98f6",
   "metadata": {},
   "source": [
    "## Receiver-Operator Characteristic\n",
    "\n",
    "A Receiver-Operator Characteristic (ROC) curve plots 1 - specificity vs. sensitivity at varying probability threshold. The area under this curve is known as the AUROC (or sometimes just \"Area Under the Curve\", AUC) and it is a well-used measure of discriminination that was originally developed by radar operators in the 1940s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c204caa0-fc2c-4bc5-aa12-12e0e3de889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.RocCurveDisplay.from_estimator(reg, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24757ede-9ec7-47d1-922d-35d310d9856a",
   "metadata": {},
   "source": [
    "An AUROC of 0.5 is no better than guessing and an AUROC of 1.0 is perfect. An AUROC of 0.9 tells us that the 90% of times our model will assign a higher risk to a randomly selected patient with an event that to a randomly selected patient without an event. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f44081-6339-42e9-986e-56db3d86bd51",
   "metadata": {},
   "source": [
    "## Key Points\n",
    "\n",
    "* Confusion matrices are the basis for many popular performance metrics.\n",
    "* AUROC is the area under the receiver operating characteristic. 0.5 is bad!\n",
    "* TP is True Positive, meaning that our prediction hit its target. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9d4fe-121e-413a-8b62-df6fb546ac22",
   "metadata": {},
   "source": [
    "# Part 7 - Bootstrapping \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd1792-5ab4-46a0-a2e2-79adea2f1958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49874b5f-e85a-400f-8ad1-4b41f7297463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaf94942-ee9e-433a-acf1-38189c9d8dff",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* Carpentries Incubator - [Introduction to Machine Learning in Python](https://carpentries-incubator.github.io/machine-learning-novice-python/)\n",
    "* Wikipedia - [Machine learning](https://en.wikipedia.org/wiki/Machine_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c876e64-ba45-4c70-876e-796a47b0fd58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
